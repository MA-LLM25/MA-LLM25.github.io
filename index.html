<!doctype html>
<html>

<head>
  <title>MA-LLM25 - ACM MM 2025 Workshop</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/footer.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
    .section {
      margin-bottom: 20px;
    }
    .section h2 {
      font-size: 24px;
      color: #333;
    }
    .section p, .section ul {
      font-size: 16px;
      color: #555;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="banner" style="background: url('img/River_liffey.jpg') no-repeat center; background-size: cover; height: 1001px;"></div>
    <div class="banner">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">ACM MM 2025 Workshop on Multimedia Analytics with Multimodal Large Language Models</h2>
            <p class="text">
              This workshop, held at ACM MM 2025, explores how Multimodal Large Language Models (MLLMs) are transforming multimedia analysis. The event will 
              feature expert talks, panel discussions, and paper presentations covering the latest advancements.
            </p>
          </div>
        </div>
      </div>
    </div>

      <!-- News Section -->
      <div class="content">
      <div class="section" id="news">
        <h2>News</h2>
        <ul>
          <li><strong>2025 March: </strong> Workshop Accepted! Our workshop has been officially accepted at ACM MM 2025.</li>
          <li><strong>2025 March: </strong> Website Launched: The MA-LLM25 workshop website is now launched.</li>
        </ul>
      </div>
    </div>

    <div class="content">
      <div class="section" id="scope">
        <h2>Scope</h2>
        <p>
          Getting insight in large multimedia collections is crucial in many domains. The emergence of Multimodal Large Language Models (MLLMs) has 
          given an unprecedented boost in the accuracy and applicability of multimedia analysis. The primary way of interacting with those models, however, 
          is still via text-based prompting or conversational agents. Text-based interaction adds an intermediate layer, thereby obfuscating the underlying data, 
          which is a cumbersome way of getting insight from multimedia data.
        </p>
        <p>
          Multimedia analytics, on the other hand, combines techniques from multimedia analysis, visualization, and data mining for extracting insights from large-scale 
          multimedia collections. The synergetic interaction between expert and machine is crucial in this process as it allows for expert-driven extraction of rich and 
          diverse insights. Visualizations can enable such interaction, by presenting scalable views of datasets, ranging from high-level summaries of collections to individual 
          data-points, compact summaries of results, and possible navigation directions for exploration. Interactive visualizations combined with multimodal conversational agents, 
          have the potential to significantly widen the communication channel between humans and MLLM, yielding much more effective ways of getting insight from the data.
        </p>
        <p>
          Realizing this potential raises a number of questions for Multimedia Analytics, such as: 
        </p>
        <ul>
          <li>What types of visualizations are most suited for getting insight in large scale multimedia collections?</li>
          <li>Can multimedia analytics be used to introduce notions of scale, currently missing in MLLMs?</li>
          <li>How to best incorporate new modes of interaction into Multimedia Analytics systems to leverage the capabilities of MLLMs and address their limitations?</li>
          <li>How to leverage interactively provided expert knowledge to improve the MLLM?</li>
          <li>How much explainability by the model is needed to let the user make informed decisions?</li>
          <li>What is the role of task-specialised interactive agents in application-driven research and how can we develop such agents?</li>
          <li>How can we develop reinforcement learning based strategies to support users in getting to their goals?</li>
          <li>What kind of system architectures are needed to work effectively with MMLMs in a multimedia analytics context?</li>
        </ul>
      </div>

      
    </div>
  </div>
  <div class="footer-container"></div>
</body>

</html>
